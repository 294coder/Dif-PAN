optimizer:
  name: 'adam'
  lr: !!float 5e-4
  weight_decay: !!float 1e-7

lr_scheduler:
  name: 'cos_anneal'
  T_max: 200
  eta_min: !!float 1e-7
#  name: 'multi_step'
#  milestones: [150, 300, 500, 700, 900]
#  gamma: 0.5

max_norm: 0.003

path:
  train_path: '/Data2/DataSet/pansharpening/training_data/train_wv3.h5'
  val_path: '/Data2/DataSet/pansharpening/training_data/valid_wv3.h5'

network_configs:
  panformer_single_scale:
    in_c: 8
    hidden_c: 64
    out_c: 8
    patch_size: !!python/tuple [ 4, 4 ]
    ms_size: !!python/tuple [ 16, 16 ]
    pan_size: !!python/tuple [ 64, 64 ]
  panformer_Unet_multi_scale:
    in_c: 8
    hidden_c: 64
    multi_channels: !!python/tuple [ 12, 24, 32 ]
    nhead: !!python/tuple [ 2, 4, 8, 2 ]
    attn_drop: !!python/tuple [ 0.2, 0.2, 0., 0. ]
    drop_path: !!python/tuple [ 0.1, 0.1, 0., 0. ]
    mlp_ratio: !!python/tuple [ 2, 2, 4, 4 ]
    mlp_drop: !!python/tuple [ 0.2, 0.2, 0., 0. ]
  panformer_switch_qkv:
    in_c: 8
    hidden_c: 128
    multi_channels: !!python/tuple [ 27, 54, 108 ]
    nhead: !!python/tuple [ 2, 4, 8, 8 ]
    attn_drop: !!python/tuple [ 0., 0.2, 0.2, 0.2 ]
    drop_path: !!python/tuple [ 0.1, 0.2, 0.4, 0.4 ]
    mlp_ratio: !!python/tuple [ 2, 2, 4, 4 ]
    mlp_drop: !!python/tuple [ 0.1, 0.2, 0.4, 0.4 ]
  panformer_restormer:
    in_c: 8
    hidden_c: 128
    multi_channels: !!python/tuple [ 16, 32, 64 ]
    nhead: !!python/tuple [ 2, 4, 4, 12 ]
    attn_drop: !!python/tuple [ 0., 0.2, 0.2, 0.2 ]
    drop_path: !!python/tuple [ 0.1, 0.2, 0.2, 0.2 ]
    mlp_ratio: !!python/tuple [ 2, 2, 4, 4 ]
    mlp_drop: !!python/tuple [ 0.1, 0.2, 0.2, 0.2 ]
  panformer_gau:
    in_c: 8
    hidden_c: 64
    multi_channels: !!python/tuple [ 16, 32, 64 ]
    depth: 4
    attn_drop: !!python/tuple [ 0., 0.2, 0.4, 0.4 ]
  panformer_sga:
    in_c: 8
    hidden_c: 128
    multi_channels: !!python/tuple [ 16, 32, 64 ]
    nhead: !!python/tuple [ 2, 4, 4, 12 ]
    attn_drop: !!python/tuple [ 0., 0.2, 0.2, 0.2 ]
    drop_path: !!python/tuple [ 0.1, 0.2, 0.2, 0.2 ]
    mlp_ratio: !!python/tuple [ 2, 2, 4, 4 ]
    mlp_drop: !!python/tuple [ 0.1, 0.2, 0.2, 0.2 ]
  panformer_dynamic:
    in_c: 8
    hidden_c: 128
    multi_channels: !!python/tuple [ 16, 32, 64 ]
    nhead: !!python/tuple [ 2, 4, 4, 12 ]
    attn_drop: !!python/tuple [ 0., 0.2, 0.2, 0.2 ]
    drop_path: !!python/tuple [ 0.1, 0.2, 0.2, 0.2 ]
    mlp_ratio: !!python/tuple [ 2, 2, 8, 2 ]
    mlp_drop: !!python/tuple [ 0.1, 0.2, 0.2, 0.2 ]